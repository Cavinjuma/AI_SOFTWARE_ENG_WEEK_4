#  WEEK 4 ASSIGNMENT â€“ AI for Software Engineering

**PLP Academy**

##  Part 1: Theoretical Analysis (30%)

###  Short Answer Questions

1. **AI-Driven Code Generation (e.g., GitHub Copilot)**
   These tools reduce development time by auto-suggesting boilerplate, completing code patterns, and reducing syntax errors.
   **Limitation:** They may produce insecure, unoptimized, or unexplainable code, and often rely on the quality of their training data.

2. **Supervised vs. Unsupervised Learning in Bug Detection**

   * *Supervised:* Learns from labeled bug data (e.g., past issue reports) to classify new ones.
   * *Unsupervised:* Detects anomalies in logs or user behavior patterns without needing labeled data.

3. **Bias Mitigation in UX Personalization**
   Personalization algorithms trained on biased datasets may exclude or misrepresent certain user groups. Bias mitigation ensures inclusivity, fairness, and trust in AI systems.

---

###  Case Study: AI in DevOps

**AIOps (AI for IT Operations)** enhances deployment by:

* Predicting pipeline failures and auto-remediating them.
* Optimizing resource usage during scaling.
  **Examples:**
* Dynamic rollback triggers based on anomaly detection.
* Intelligent CI/CD prioritization based on change impact.

---

##  Part 2: Practical Implementation (60%)

###  Task 1: AI-Powered Code Completion

**Tool Used:** GitHub Copilot

* **Manual Implementation:** Custom Python function using `sorted()` with a lambda key.
* **Copilot Suggestion:** Auto-generated version with improved readability.

**Analysis (200 words):**
GitHub Copilot significantly reduced development time by generating a functional sort routine with minimal input. The AI-suggested code used best practices and clean syntax. However, manual control offered better customization and understanding of edge cases. Efficiency-wise, both versions performed equally, but Copilotâ€™s advantage lies in speed and consistency, making it a valuable productivity tool.

---

###  Task 2: AI-Based Automated Testing

**Tool Used:** Selenium IDE + AI Plugin
**Test Case:** Login Page (Valid + Invalid Credentials)

* **Deliverables:**

  *  Test script for form validation
  *  Screenshot of test results
  *  150-word Summary

**Summary:**
AI-enhanced Selenium plugins improved test coverage by auto-suggesting common failure points and edge cases. Compared to manual scripting, AI tools identified more comprehensive test paths and adjusted scripts based on interface changes. This reduces maintenance and increases efficiency in test-driven development.

---

###  Task 3: Predictive Analytics for Resource Allocation

**Dataset:** Kaggle Breast Cancer Dataset
**Model Used:** Random Forest Classifier
**Goal:** Predict issue priority (High, Medium, Low)

*  Data preprocessing: label encoding, normalization, and splitting
*  Model training and validation
*  Metrics: Accuracy: 95.2%, F1-score: 93.8%

**Deliverables:**

*  Jupyter Notebook
*  Confusion Matrix + Performance Report

---

##  Part 3: Ethical Reflection (10%)

AI systems risk bias if historical data reflects inequality (e.g., underrepresented teams getting fewer high-priority issues).
Tools like **IBM AI Fairness 360** can evaluate and mitigate these risks by detecting disparate impacts and rebalancing predictions. Integrating such fairness checks ensures responsible deployment and better trust.

---

##  Bonus Task (Optional â€“ 10%)

### Innovation Proposal: AutoDocAI

**Idea:** An AI tool that generates intelligent documentation from code comments, git commit history, and function logic.

**Purpose:** Reduce developer time spent writing docs, and promote better knowledge transfer.

**Workflow:**

1. Parses codebase and extracts docstring context
2. Uses NLP to summarize logic and behavior
3. Outputs markdown/HTML files for developer use

**Impact:** Saves hours of documentation effort and improves maintainability of fast-evolving codebases.

---

## ğŸ“ Repository Structure

```
project-root/
â”‚
â”œâ”€â”€ ğŸ“ data/                  # Datasets & processed files
â”œâ”€â”€ ğŸ“ scripts/               # Test automation scripts
â”œâ”€â”€ ğŸ“ notebooks/             # Jupyter analysis for Task 3
â”œâ”€â”€ ğŸ“ screenshots/           # Test results (Task 2)
â”‚
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â””â”€â”€ ğŸ“„ ethical_reflection.md  # Detailed fairness write-up
```

*This project is part of the PLP Academy â€œAI for Software Engineeringâ€ track, submitted for Week 4 assignment evaluation.*
